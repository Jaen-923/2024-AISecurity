{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3WriV9ifW46x",
      "metadata": {
        "id": "3WriV9ifW46x"
      },
      "source": [
        "# XOR 구현:\n",
        "\n",
        "Multiple Layer Perceptron을 사용하여 XOR를 구현하기<br>\n",
        "activation function: 사용안함<br>\n",
        "XOR 모델을 class 형태로 구현할 것<br>\n",
        "Train 함수를 구현할 것<br>\n",
        "훈련된 XOR 모델을 통해 y를 출력하여, XOR gate의 출력을 만족하는지 확인하시오.<br>\n",
        "            * y가 0.5 이상은 1, 반대는 0으로 산출할 것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "id": "EgrO12bdWw60",
      "metadata": {
        "id": "EgrO12bdWw60"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "id": "L97vah9WYjVt",
      "metadata": {
        "id": "L97vah9WYjVt"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
        "Y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "id": "WMWXXiOGWxDY",
      "metadata": {
        "id": "WMWXXiOGWxDY"
      },
      "outputs": [],
      "source": [
        "class XOR_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XOR_Model, self).__init__()\n",
        "        self.hidden_layer = nn.Linear(2, 4)\n",
        "        self.output_layer = nn.Linear(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden_layer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "id": "h4kaSlnkXRtQ",
      "metadata": {
        "id": "h4kaSlnkXRtQ"
      },
      "outputs": [],
      "source": [
        "def train(model, X, Y):\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
        "\n",
        "    epochs=9000\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        loss = loss_fn(hypothesis, Y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "id": "WJLqUT6SXR2E",
      "metadata": {
        "id": "WJLqUT6SXR2E"
      },
      "outputs": [],
      "source": [
        "# 데이터 및 모델 초기화\n",
        "model = XOR_Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "id": "QnZsiDnPXR9G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnZsiDnPXR9G",
        "outputId": "068147d4-84f4-4da7-ce58-cc6af1134373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000, Loss: 0.25000184774398804\n",
            "Epoch: 2000, Loss: 0.25\n",
            "Epoch: 3000, Loss: 0.25\n",
            "Epoch: 4000, Loss: 0.2499999701976776\n",
            "Epoch: 5000, Loss: 0.2499999701976776\n",
            "Epoch: 6000, Loss: 0.2499999701976776\n",
            "Epoch: 7000, Loss: 0.2499999701976776\n",
            "Epoch: 8000, Loss: 0.2499999701976776\n",
            "Epoch: 9000, Loss: 0.2499999701976776\n"
          ]
        }
      ],
      "source": [
        "train(model, X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "id": "cMck_kuKXcN3",
      "metadata": {
        "id": "cMck_kuKXcN3"
      },
      "outputs": [],
      "source": [
        "# 훈련된 모델로 XOR 출력 확인\n",
        "def predict(x, model):\n",
        "    with torch.no_grad():\n",
        "        output = model(x)\n",
        "        if output.item() >= 0.5:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "id": "62gd6cFKJL0j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62gd6cFKJL0j",
        "outputId": "f0835c42-c6ee-4c7d-a825-87bb52fdc4a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 데이터 정확도: 0.75\n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(model, X_test, Y_test):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in zip(X_test, Y_test):\n",
        "            prediction = predict(x, model=model)\n",
        "            if prediction == y.item():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# 테스트 데이터에 대한 정확도 계산\n",
        "accuracy = calculate_accuracy(model, X, Y)\n",
        "print(f'테스트 데이터 정확도: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "id": "vWO1JyoXXcQu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWO1JyoXXcQu",
        "outputId": "0453569a-211c-45a3-ccf7-c6f990f8ea99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XOR 구현\n",
            "tensor([0., 0.]) 0.5000021457672119 1\n",
            "tensor([0., 1.]) 0.5000000596046448 1\n",
            "tensor([1., 0.]) 0.5000002384185791 1\n",
            "tensor([1., 1.]) 0.4999980330467224 0\n"
          ]
        }
      ],
      "source": [
        "print(\"XOR 구현\")\n",
        "for x in X:\n",
        "    print(x, model(x).item(),predict(x, model=model))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
